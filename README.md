# Proyecto: Clasificaci√≥n de flores con CNN + Streamlit

Estructura Final del Proyecto:
De datos se uso un dataset de flores, el dataset se descargo de kaggle: https://www.kaggle.com/datasets/imsparsh/flowers-dataset?resource=download
Para el modelo se realizo un modelo CNN basico para la clasificacion de estas en donde se desarrollo y probo en GoogleColab: https://colab.research.google.com/drive/1xlOT2T1lpqWGn3ux1O_OX2qIlGJFoS5P?usp=sharing
En el streamlit se uso el script: app.py, el cual tiene toda la estructura basica para la app funcional que carga una imagen de una flor, la clasifica, predice y nos da un porcentaje de confiabilidad, C√≥digo principal de Streamlit
Requeriments. txt tiene toda las librerias basicas necesasrias que necesitamos para desarrollar nuestra app


Este proyecto permite clasificar im√°genes de flores usando una red neuronal convolucional (CNN) construida en PyTorch, integrada en una aplicaci√≥n web hecha con Streamlit.

## üöÄ ¬øQu√© incluye?

- Red neuronal convolucional (CNN) simple.
- Clasificaci√≥n de 5 clases de flores: daisy, dandelion, rose, sunflower, tulip.
- Subida de im√°genes en Streamlit.
- Predicci√≥n en tiempo real con el modelo preentrenado.
- Visualizaci√≥n de la probabilidad de predicci√≥n.

## Instalaci√≥n

1. Clona el repositorio:
    ```bash
    git clone https://github.com/tu_usuario/tu_repositorio.git
    cd tu_repositorio
    ```
Debes descomprimir el archivo.zip que se descarga en el repositorio Kaggle

2. Crea y activa un entorno virtual en tu computadora:
    ```bash
    python -m venv venv
    # Activar en Windows:
    .\venv\Scripts\activate
    ```

3. Instala las dependencias:
    ```bash
    pip install -r requirements.txt
    ```
Nota: dees tener en cuenta que debes asegurarte de tener Streamlit, Pytorch, Python y descargar el modelo,pth del google colab o tener una ya previamente entrenado

4. Ejecuta la app:
    ```bash
    streamlit run app.py
    ```
----------------------------------------------
# En cueanto a lo que se realizo en el script de Google Colab:

1. Librer√≠as Importadas:
Se importaron las siguientes librer√≠as necesarias para procesamiento de im√°genes, construcci√≥n de redes neuronales y visualizaci√≥n:

- torch, torch.nn, torch.optim: para crear y entrenar la CNN.
- pytorch_lightning: para estructurar de manera m√°s ordenada el flujo de datos.
- matplotlib.pyplot: para visualizar im√°genes.
- numpy, PIL.Image, os, pandas: para manejo de datos y archivos.
- torchvision.transforms: para preprocesamiento de im√°genes.

2. Creaci√≥n de un Dataset personalizado
Se defini√≥ una clase Dataset personalizada:

class Dataset(torch.utils.data.Dataset) que recibe una lista de rutas de im√°genes y etiquetas, se carga cada imagen usando PIL.Image, se aplica transformaciones como redimensionamiento y conversi√≥n a tensor y 
devuelve cada imagen y su respectiva etiqueta como un torch.Tensor con el objetivo de preparar los datos para ser usados por PyTorch de forma compatible.

3.  Preprocesamiento y manejo de datos - FlowerDataModule
Se defini√≥ la clase:
class FlowerDataModule(pl.LightningDataModule) para la carga im√°genes desde carpetas train/ organizadas por clases (por ejemplo: train/daisy, train/rose...), se asigna un √≠ndice a cada clase autom√°ticamente.
Separa los datos en:
80% para entrenamiento - 20% para validaci√≥n

Se aplica transformaciones de:
- Redimensionar todas las im√°genes a 128x128 p√≠xeles.
- Convertirlas en tensores normalizados.
- Proporciona dataloaders para el entrenamiento (train_dataloader()) y la validaci√≥n (val_dataloader()).

4. Visualizaci√≥n de im√°genes
Se visualizaron 64 im√°genes del dataset de entrenamiento, se organizaron en un grid de 8 filas x 8 columnas, cada imagen se mostr√≥ junto con su etiqueta predicha,
se transformaron de formato [C, H, W] a [H, W, C] para que puedan ser interpretadas por matplotlib para verificar que el preprocesamiento de datos es correcto antes de entrenar.

5.  Definici√≥n del modelo SimpleCNN
Se defini√≥ la red neuronal convolucional SimpleCNN:

class SimpleCNN(nn.Module):
De la cual su arquitectura es:
- Entrada: im√°genes RGB (3 canales).
- Capas:
Convoluci√≥n 1: 32 filtros, kernel 3x3, padding 1 ‚Üí seguida de ReLU y MaxPooling.
Convoluci√≥n 2: 64 filtros, kernel 3x3, padding 1 ‚Üí seguida de ReLU y MaxPooling.
Aplanado (Flatten).
Capa densa: 64x32x32 ‚Üí 128 neuronas ‚Üí ReLU.
Capa final de clasificaci√≥n: 128 ‚Üí 5 neuronas (una por cada clase de flor).

S contruyo para que sea simple, eficiente y suficiente para un problema de clasificaci√≥n b√°sico con im√°genes peque√±as.

6.  Entrenamiento del modelo
Se defini√≥ una funci√≥n train:

def train(model, datamodule, epochs=5, lr=1e-3, device='cuda' if torch.cuda.is_available() else 'cpu'):

Esta carga los datos de entrenamiento y validaci√≥n. 

Usa:
- Funci√≥n de p√©rdida: CrossEntropyLoss (para clasificaci√≥n multiclase).
- Optimizador: Adam con learning rate de 0.001.

Realiza 5 √©pocas de entrenamiento:
- Propagaci√≥n hacia adelante (forward).
- C√°lculo de la p√©rdida.
- Propagaci√≥n hacia atr√°s (backward).
- Actualizaci√≥n de pesos (optimizer.step).

Eval√∫a desempe√±o tanto en entrenamiento como en validaci√≥n, imprimiendo:
- P√©rdida promedio (avg_loss).
- Precisi√≥n (train_acc y val_acc).

Resultados:
Cada √©poca muestra el progreso del entrenamiento y la calidad de la validaci√≥n.
Epoch 1/5 - Train Loss: 1.3674, Train Acc: 0.4076, Val Acc: 0.0000
Epoch 2/5 - Train Loss: 0.9900, Train Acc: 0.6011, Val Acc: 0.0000
Epoch 3/5 - Train Loss: 0.8309, Train Acc: 0.6726, Val Acc: 0.0036
Epoch 4/5 - Train Loss: 0.7204, Train Acc: 0.7272, Val Acc: 0.0018
Epoch 5/5 - Train Loss: 0.5991, Train Acc: 0.7755, Val Acc: 0.0636

7.  Guardado y carga del modelo
Despu√©s del entrenamiento, el modelo se guard√≥ usando:

def save_model(model, path='model_cnn.pth'): El cual solo se guardaron solo los pesos (state_dict) en el archivo model_cnn.pth para cargarlo m√°s r√°pido y ocupar menos espacio.

Para cargar el modelo despu√©s se us√≥:

def load_model(model_class, path='model_cnn.pth', device='cuda' if torch.cuda.is_available() else 'cpu'): Que carga correctamente los pesos en la misma arquitectura SimpleCNN.

8. Preparaci√≥n del dataset de prueba: TestDataset
Se defini√≥ la clase -> class TestDataset(Dataset):
La cual carga im√°genes sueltas de la carpeta test/ (sin subcarpetas).
Usa un CSV (Testing_set_flower.csv) que contiene el nombre de cada archivo.
Solo devuelve las im√°genes y sus nombres, sin etiquetas reales (no se usa ground truth).

Transformaci√≥n aplicada: 
- Redimensiona a 128x128 p√≠xeles.
- Conversi√≥n a tensor.

9.  Inferencia en el conjunto de prueba
Se defini√≥ una -> def mostrar_predicciones_solo_pred(model, test_dataset, idx_to_class, n=5, device='cuda' if torch.cuda.is_available() else 'cpu'):
Para que seleccione aleatoriamente 5 im√°genes del dataset de prueba, pasa cada imagen por el modelo, predice la clase (√≠ndice m√°ximo del vector de salida) y traduce el √≠ndice al nombre de la flor
usando el diccionario idx_to_class.

Muestra:
- Imagen
- Nombre de archivo
- Clase predicha

Visualizaci√≥n:
- Im√°genes en una fila horizontal (o varias si se necesita).
- Etiquetas predichas como t√≠tulo de cada imagen.

Resultado final
Se entren√≥ una CNN b√°sica capaz de clasificar 5 tipos de flores, se guard√≥ el modelo para inferencia futura, se construy√≥ un pipeline completo de: Carga de datos, Preprocesamiento, Entrenamiento, Validaci√≥n y 
Predicci√≥n en im√°genes nuevas.

Todo el sistema es reutilizable y puede integrarse f√°cilmente como se realizo en Streamlit.

Conclusi√≥n
El proyecto completo de Google Colab posee:

- Preparaci√≥n y carga de im√°genes.
- Dise√±o e implementaci√≥n de una CNN sencilla.
- Entrenamiento supervisado en un conjunto de datos propio.
- Guardado y carga de modelos de PyTorch.
- Realizaci√≥n de inferencia sobre datos nuevos.
- Visualizaci√≥n de resultados de forma clara.

  Gracias por leer!

